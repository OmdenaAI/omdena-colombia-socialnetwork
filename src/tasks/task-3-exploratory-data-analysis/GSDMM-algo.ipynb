{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gsdmm import MovieGroupProcess\n",
    "import nltk\n",
    "import unicodedata\n",
    "#import re\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df = pd.read_csv('/Users/inna/Documents/GitHub/omdena-colombia-socialnetwork/src/data/task-2-preprocessing/merged_data/Final/Final_all.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>conversation_id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>twitter_lang</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>preprocessed_data</th>\n",
       "      <th>emoji_list</th>\n",
       "      <th>emoticons_list</th>\n",
       "      <th>filename</th>\n",
       "      <th>preprocessed_data_without_hashtags</th>\n",
       "      <th>data_source</th>\n",
       "      <th>lang</th>\n",
       "      <th>score</th>\n",
       "      <th>langTb</th>\n",
       "      <th>lang_langdetect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-27T04:09:42+00:00</td>\n",
       "      <td>1.375661e+18</td>\n",
       "      <td>1.375265e+18</td>\n",
       "      <td>@Diputado_Canelo Hagamos otro por el uno de ma...</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['hacer', 'mayo', 'cazar', 'fantasma', 'mayo']</td>\n",
       "      <td>['']</td>\n",
       "      <td>[':/']</td>\n",
       "      <td>Mayo_SPANISH_tweets_stweet.csv</td>\n",
       "      <td>['hacer', 'mayo', 'cazar', 'fantasma']</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-22T21:12:09+00:00</td>\n",
       "      <td>1.374107e+18</td>\n",
       "      <td>1.374107e+18</td>\n",
       "      <td>Despu√©s de esperar con ancias el #28F ahora es...</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['despues', 'esperar', 'ancia', 'ahora', 'espe...</td>\n",
       "      <td>['üíôü§çüíô']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Mayo_SPANISH_tweets_stweet.csv</td>\n",
       "      <td>['despues', 'esperar', 'ancia', 'ahora', 'espe...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-22T12:30:53+00:00</td>\n",
       "      <td>1.373975e+18</td>\n",
       "      <td>1.373975e+18</td>\n",
       "      <td>Espero que √©sto llegue hasta o√≠dos de la nueva...</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['esperar', 'llegar', 'oido', 'nuevo', 'inicia...</td>\n",
       "      <td>['']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Mayo_SPANISH_tweets_stweet.csv</td>\n",
       "      <td>['esperar', 'llegar', 'oido', 'nuevo', 'inicia...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-04-04T12:56:55+00:00</td>\n",
       "      <td>1.378693e+18</td>\n",
       "      <td>1.378693e+18</td>\n",
       "      <td>A menos de un mes del #1Mayo Urkullu teme perd...</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['menos', 'mes', 'mayo', 'urkullu', 'temer', '...</td>\n",
       "      <td>['']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Mayo_SPANISH_tweets_stweet.csv</td>\n",
       "      <td>['menos', 'mes', 'urkullu', 'temer', 'perder',...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-04-03T20:14:57+00:00</td>\n",
       "      <td>1.378441e+18</td>\n",
       "      <td>1.378441e+18</td>\n",
       "      <td>La X Edici√≥n del Festival Internacional Un Pue...</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['edicion', 'festival', 'internacional', 'puen...</td>\n",
       "      <td>['']</td>\n",
       "      <td>[':/', ':/']</td>\n",
       "      <td>Mayo_SPANISH_tweets_stweet.csv</td>\n",
       "      <td>['edicion', 'festival', 'internacional', 'puen...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 created_at        id_str  conversation_id_str  \\\n",
       "0           0  2021-03-27T04:09:42+00:00  1.375661e+18         1.375265e+18   \n",
       "1           1  2021-03-22T21:12:09+00:00  1.374107e+18         1.374107e+18   \n",
       "2           2  2021-03-22T12:30:53+00:00  1.373975e+18         1.373975e+18   \n",
       "3           3  2021-04-04T12:56:55+00:00  1.378693e+18         1.378693e+18   \n",
       "4           4  2021-04-03T20:14:57+00:00  1.378441e+18         1.378441e+18   \n",
       "\n",
       "                                           full_text twitter_lang favorited  \\\n",
       "0  @Diputado_Canelo Hagamos otro por el uno de ma...           es     False   \n",
       "1  Despu√©s de esperar con ancias el #28F ahora es...           es     False   \n",
       "2  Espero que √©sto llegue hasta o√≠dos de la nueva...           es     False   \n",
       "3  A menos de un mes del #1Mayo Urkullu teme perd...           es     False   \n",
       "4  La X Edici√≥n del Festival Internacional Un Pue...           es     False   \n",
       "\n",
       "  retweeted  retweet_count  favorite_count  ...  \\\n",
       "0     False            0.0             1.0  ...   \n",
       "1     False            1.0             4.0  ...   \n",
       "2     False            0.0             1.0  ...   \n",
       "3     False            3.0             5.0  ...   \n",
       "4     False            1.0             3.0  ...   \n",
       "\n",
       "                                   preprocessed_data  emoji_list  \\\n",
       "0     ['hacer', 'mayo', 'cazar', 'fantasma', 'mayo']        ['']   \n",
       "1  ['despues', 'esperar', 'ancia', 'ahora', 'espe...     ['üíôü§çüíô']   \n",
       "2  ['esperar', 'llegar', 'oido', 'nuevo', 'inicia...        ['']   \n",
       "3  ['menos', 'mes', 'mayo', 'urkullu', 'temer', '...        ['']   \n",
       "4  ['edicion', 'festival', 'internacional', 'puen...        ['']   \n",
       "\n",
       "   emoticons_list                        filename  \\\n",
       "0          [':/']  Mayo_SPANISH_tweets_stweet.csv   \n",
       "1              []  Mayo_SPANISH_tweets_stweet.csv   \n",
       "2              []  Mayo_SPANISH_tweets_stweet.csv   \n",
       "3              []  Mayo_SPANISH_tweets_stweet.csv   \n",
       "4    [':/', ':/']  Mayo_SPANISH_tweets_stweet.csv   \n",
       "\n",
       "                  preprocessed_data_without_hashtags  data_source lang score  \\\n",
       "0             ['hacer', 'mayo', 'cazar', 'fantasma']      Twitter   es   NaN   \n",
       "1  ['despues', 'esperar', 'ancia', 'ahora', 'espe...      Twitter   es   NaN   \n",
       "2  ['esperar', 'llegar', 'oido', 'nuevo', 'inicia...      Twitter   es   NaN   \n",
       "3  ['menos', 'mes', 'urkullu', 'temer', 'perder',...      Twitter   es   NaN   \n",
       "4  ['edicion', 'festival', 'internacional', 'puen...      Twitter   es   NaN   \n",
       "\n",
       "  langTb  lang_langdetect  \n",
       "0    NaN              NaN  \n",
       "1    NaN              NaN  \n",
       "2    NaN              NaN  \n",
       "3    NaN              NaN  \n",
       "4    NaN              NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "docs = df['preprocessed_data']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next cell, I call on MovieGroupProcess to do the clustering of topics.\n",
    "One thing to keep in mind is to adjust the (alpha) and (beta) values to whatever is best suited for the data. Also, adjust (n_iters) to a number that‚Äôs high enough for the model to converge and stabilize.Adjust (K) to a number that‚Äôs sufficient enough to cover the number of clusters.\n",
    "https://towardsdatascience.com/gsdmm-topic-modeling-for-social-media-posts-and-reviews-8726489dc52f"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "mgp = MovieGroupProcess(K=15, alpha=0.1, beta=1, n_iters=30)\n",
    "\n",
    "vocab = set(x for doc in docs for x in doc)\n",
    "n_terms = len(vocab)\n",
    "\n",
    "y = mgp.fit(docs, n_terms)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In stage 0: transferred 20724 clusters with 15 clusters populated\n",
      "In stage 1: transferred 14762 clusters with 15 clusters populated\n",
      "In stage 2: transferred 9899 clusters with 15 clusters populated\n",
      "In stage 3: transferred 8154 clusters with 15 clusters populated\n",
      "In stage 4: transferred 7533 clusters with 14 clusters populated\n",
      "In stage 5: transferred 7230 clusters with 14 clusters populated\n",
      "In stage 6: transferred 7267 clusters with 14 clusters populated\n",
      "In stage 7: transferred 7221 clusters with 14 clusters populated\n",
      "In stage 8: transferred 7203 clusters with 13 clusters populated\n",
      "In stage 9: transferred 7145 clusters with 13 clusters populated\n",
      "In stage 10: transferred 7027 clusters with 13 clusters populated\n",
      "In stage 11: transferred 6950 clusters with 13 clusters populated\n",
      "In stage 12: transferred 6951 clusters with 13 clusters populated\n",
      "In stage 13: transferred 6981 clusters with 13 clusters populated\n",
      "In stage 14: transferred 6881 clusters with 13 clusters populated\n",
      "In stage 15: transferred 6916 clusters with 13 clusters populated\n",
      "In stage 16: transferred 6704 clusters with 13 clusters populated\n",
      "In stage 17: transferred 6650 clusters with 13 clusters populated\n",
      "In stage 18: transferred 6737 clusters with 13 clusters populated\n",
      "In stage 19: transferred 6577 clusters with 13 clusters populated\n",
      "In stage 20: transferred 6639 clusters with 13 clusters populated\n",
      "In stage 21: transferred 6523 clusters with 13 clusters populated\n",
      "In stage 22: transferred 6482 clusters with 13 clusters populated\n",
      "In stage 23: transferred 6441 clusters with 13 clusters populated\n",
      "In stage 24: transferred 6244 clusters with 13 clusters populated\n",
      "In stage 25: transferred 6133 clusters with 13 clusters populated\n",
      "In stage 26: transferred 6050 clusters with 13 clusters populated\n",
      "In stage 27: transferred 5817 clusters with 13 clusters populated\n",
      "In stage 28: transferred 5643 clusters with 13 clusters populated\n",
      "In stage 29: transferred 5545 clusters with 13 clusters populated\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of documents per topic : [1316 1932  253  277 1110    0   57  458  402 3294   98 7696    0   89\n",
      " 5178]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "top_index = doc_count.argsort()[-15:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most important clusters (by number of docs inside): [11 14  9  1  0  4  7  8  3  2 10 13  6 12  5]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print('Cluster %s : %s'%(cluster,sort_dicts))\n",
    "        print('-'*120)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "top_words(mgp.cluster_word_distribution, top_index, 7)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cluster 11 : [(\"'\", 206368), ('a', 98990), (',', 95502), (' ', 95500), ('o', 78772), ('r', 76446), ('e', 74252)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 14 : [(\"'\", 344477), (' ', 167085), (',', 167084), ('a', 126884), ('e', 120215), ('o', 115369), ('i', 97354)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 9 : [(\"'\", 61004), ('o', 41432), ('a', 36216), (',', 27219), (' ', 27219), ('i', 25392), ('s', 21549)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 1 : [(\"'\", 31882), ('a', 23328), ('o', 18143), ('i', 14817), (',', 14011), (' ', 14011), ('r', 13859)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 0 : [(\"'\", 33056), (',', 15216), (' ', 15216), ('o', 13697), ('a', 11948), ('e', 11901), ('i', 9375)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 4 : [(\"'\", 18494), ('a', 14440), ('o', 13166), ('e', 9834), ('i', 8666), ('s', 8567), ('n', 8309)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 7 : [(\"'\", 13897), (',', 6493), (' ', 6493), ('e', 3722), ('t', 3006), ('o', 2780), ('i', 2343)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 8 : [('o', 2869), ('a', 2275), (\"'\", 2092), ('d', 1467), ('s', 1365), ('h', 1286), ('l', 1141)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 3 : [(\"'\", 4768), ('o', 3523), ('a', 3424), (',', 2109), (' ', 2109), ('i', 1752), ('e', 1743)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 2 : [(\"'\", 8055), (',', 3797), (' ', 3797), ('a', 3230), ('o', 2801), ('r', 2466), ('e', 2461)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 10 : [(\"'\", 2712), (',', 1258), (' ', 1258), ('a', 1196), ('o', 1021), ('i', 822), ('e', 804)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 13 : [(\"'\", 1740), ('e', 1082), ('o', 903), ('r', 825), (',', 781), (' ', 781), ('a', 739)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 6 : [('a', 569), (\"'\", 482), ('j', 377), (',', 185), (' ', 185), ('r', 156), ('e', 142)]\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 12 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Cluster 5 : []\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "topic_dict = {}\n",
    "topic_names = ['Topic #1',\n",
    "               'Topic #2',\n",
    "               'Topic #3',\n",
    "               'Topic #4',\n",
    "               'Topic #5',\n",
    "               'Topic #6',\n",
    "               'Topic #7',\n",
    "               'Topic #8',\n",
    "               'Topic #9',\n",
    "               'Topic #10',\n",
    "               'Topic #11',\n",
    "               'Topic #12',\n",
    "               'Topic #13',\n",
    "               'Topic #14',\n",
    "               'Topic #15'\n",
    "              ]\n",
    "for i, topic_num in enumerate(top_index):\n",
    "    topic_dict[topic_num]=topic_names[i]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def create_topics_dataframe(data_text=df,  mgp=mgp, threshold=0.3, topic_dict=topic_dict, stem_text=docs):\n",
    "    result = pd.DataFrame(columns=['text', 'topic', 'stems'])\n",
    "    for i, text in enumerate(data_text):\n",
    "        result.at[i, 'text'] = text\n",
    "        result.at[i, 'stems'] = stem_text[i]\n",
    "        prob = mgp.choose_best_label(stem_text[i])\n",
    "        if prob[1] >= threshold:\n",
    "            result.at[i, 'topic'] = topic_dict[prob[0]]\n",
    "        else:\n",
    "            result.at[i, 'topic'] = 'Other'\n",
    "    return result\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dfx = create_topics_dataframe(data_text=df,  mgp=mgp, threshold=0.3, topic_dict=topic_dict, stem_text=docs)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "dfx.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>Topic #9</td>\n",
       "      <td>['hacer', 'mayo', 'cazar', 'fantasma', 'mayo']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>created_at</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>['despues', 'esperar', 'ancia', 'ahora', 'espe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_str</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>['esperar', 'llegar', 'oido', 'nuevo', 'inicia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conversation_id_str</td>\n",
       "      <td>Topic #2</td>\n",
       "      <td>['menos', 'mes', 'mayo', 'urkullu', 'temer', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>full_text</td>\n",
       "      <td>Topic #1</td>\n",
       "      <td>['edicion', 'festival', 'internacional', 'puen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text     topic  \\\n",
       "0           Unnamed: 0  Topic #9   \n",
       "1           created_at  Topic #1   \n",
       "2               id_str  Topic #1   \n",
       "3  conversation_id_str  Topic #2   \n",
       "4            full_text  Topic #1   \n",
       "\n",
       "                                               stems  \n",
       "0     ['hacer', 'mayo', 'cazar', 'fantasma', 'mayo']  \n",
       "1  ['despues', 'esperar', 'ancia', 'ahora', 'espe...  \n",
       "2  ['esperar', 'llegar', 'oido', 'nuevo', 'inicia...  \n",
       "3  ['menos', 'mes', 'mayo', 'urkullu', 'temer', '...  \n",
       "4  ['edicion', 'festival', 'internacional', 'puen...  "
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1b007364462035d7d7debdcae39cd66c15ca9aac683a175d7d0391bdb85e582c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}